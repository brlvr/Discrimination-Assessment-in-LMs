# Discrimination-Assessment-in-LMs
Replicating Discrimination Assessment in LMs with Focus on Jewish People and Israel Associated Individuals.
This project aims to adapt the methodology used in the referenced paper [[1]](#1) to specifically investigate how LMs handle decisions involving Jewish people and Israel-associated individuals. 
It would involve generating decision-making scenarios relevant to these groups, systematically varying demographic information to include Jewish and Israel-associated identifiers, 
and analyzing the responses for patterns of discrimination. The project would also explore prompt-based interventions to mitigate any discovered biases, 
contributing to the broader understanding of LMsâ€™ handling of specific ethnic and national identities. For more details on the original paper, you can access it [[1]](#1).


## Missions
- [ ] Read the article
- [ ] Resources
- [ ] Dataset - explore prompts, add more categories related to our work
- [ ] Evaluation - According to the paper, maybe find new ones?
- [ ] Models - Gemma-2b, Gemma-7b, Claude?, more?
- [ ] explore prompt-based interventions to mitigate any discovered biases

## 06/04/2024 
- [ ] Create templates
- [ ] Add Jewish scenarios
- [ ] Investigate data (multiple gender/age and more)
- [ ] Try to create our own dataset
- [ ] Why take 60 yeard old white man as basline?
- [ ] .




## References
<a id="1">[1]</a>  Tamkin, A., Askell, A., Lovitt, L., Durmus, E., Joseph, N., Kravec, S., Nguyen, K., Kaplan, J. and Ganguli, D., 2023. Evaluating and mitigating discrimination in language model decisions. arXiv preprint [arXiv:2312.03689](https://arxiv.org/abs/2312.03689).